---
title: クイックスタート
description: Build your first realtime voice assistant using the OpenAI Agents SDK in minutes.
---

import { Steps, Aside, Code } from '@astrojs/starlight/components';
import helloWorldExample from '../../../../../../../examples/docs/voice-agents/helloWorld.ts?raw';
import createAgentExample from '../../../../../../../examples/docs/voice-agents/createAgent.ts?raw';
import multiAgentsExample from '../../../../../../../examples/docs/voice-agents/multiAgents.ts?raw';
import createSessionExample from '../../../../../../../examples/docs/voice-agents/createSession.ts?raw';
import configureSessionExample from '../../../../../../../examples/docs/voice-agents/configureSession.ts?raw';
import handleAudioExample from '../../../../../../../examples/docs/voice-agents/handleAudio.ts?raw';
import defineToolExample from '../../../../../../../examples/docs/voice-agents/defineTool.ts?raw';
import toolApprovalEventExample from '../../../../../../../examples/docs/voice-agents/toolApprovalEvent.ts?raw';
import guardrailsExample from '../../../../../../../examples/docs/voice-agents/guardrails.ts?raw';
import guardrailSettingsExample from '../../../../../../../examples/docs/voice-agents/guardrailSettings.ts?raw';
import audioInterruptedExample from '../../../../../../../examples/docs/voice-agents/audioInterrupted.ts?raw';
import sessionInterruptExample from '../../../../../../../examples/docs/voice-agents/sessionInterrupt.ts?raw';
import sessionHistoryExample from '../../../../../../../examples/docs/voice-agents/sessionHistory.ts?raw';
import historyUpdatedExample from '../../../../../../../examples/docs/voice-agents/historyUpdated.ts?raw';
import updateHistoryExample from '../../../../../../../examples/docs/voice-agents/updateHistory.ts?raw';
import customWebRTCTransportExample from '../../../../../../../examples/docs/voice-agents/customWebRTCTransport.ts?raw';
import websocketSessionExample from '../../../../../../../examples/docs/voice-agents/websocketSession.ts?raw';
import transportEventsExample from '../../../../../../../examples/docs/voice-agents/transportEvents.ts?raw';
import thinClientExample from '../../../../../../../examples/docs/voice-agents/thinClient.ts?raw';

<Steps>

0. **プロジェクトを作成する**

   このクイックスタートでは、ブラウザで利用できる音声エージェントを作成します。新しいプロジェクトを試したい場合は、[`Next.js`](https://nextjs.org/docs/getting-started/installation) や [`Vite`](https://vite.dev/guide/installation.html) をお試しください。

   ```bash
   npm create vite@latest my-project --template vanilla-ts
   ```

1. **Agents SDK をインストールする**

   ```bash
   npm install @openai/agents 'zod@<=3.25.67'
   ```

   代わりにブラウザ用の単体パッケージである `@openai/agents-realtime` をインストールすることもできます。

2. **クライアントのエフェメラルトークンを生成する**

   このアプリケーションはユーザーのブラウザで動作するため、Realtime API を介してモデルへ安全に接続する方法が必要です。そのために、[エフェメラルクライアントキー](https://platform.openai.com/docs/guides/realtime#creating-an-ephemeral-token) をバックエンドサーバーで生成します。テスト目的であれば、`curl` と通常の OpenAI API キーを使ってキーを生成することも可能です。

   ```bash
   curl -X POST https://api.openai.com/v1/realtime/sessions \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "gpt-4o-realtime-preview-2025-06-03"
      }'
   ```

   レスポンスには後で接続に使用する `client_secret.value` が含まれます。このキーは短時間のみ有効で、再生成が必要になる点に注意してください。

3. **最初のエージェントを作成する**

   新しい [`RealtimeAgent`](/openai-agents-js/openai/agents-realtime/classes/realtimeagent/) の作成は、通常の [`Agent`](/openai-agents-js/ja/guides/agents) の作成とほぼ同じです。

   ```typescript
   import { RealtimeAgent } from '@openai/agents-realtime';

   const agent = new RealtimeAgent({
     name: 'Assistant',
     instructions: 'You are a helpful assistant.',
   });
   ```

4. **セッションを作成する**

   通常のエージェントと異なり、Voice エージェントは `RealtimeSession` 内で継続的に動作し、時間をかけてモデルとの会話と接続を管理します。このセッションは音声処理、割り込み、その他のライフサイクル機能も扱います。これらについては後ほど説明します。

   ```typescript
   import { RealtimeSession } from '@openai/agents-realtime';

   const session = new RealtimeSession(agent, {
     model: 'gpt-4o-realtime-preview-2025-06-03',
   });
   ```

   `RealtimeSession` のコンストラクターは最初の引数に `agent` を取ります。このエージェントがユーザーと最初に対話するエージェントになります。

5. **セッションへ接続する**

   先ほど生成したクライアントのエフェメラルトークンを渡してセッションへ接続します。

   ```typescript
   await session.connect({ apiKey: '<client-api-key>' });
   ```

   これによりブラウザで WebRTC を使って Realtime API に接続し、マイクとスピーカーを自動で設定して音声の入出力を行います。`RealtimeSession` をバックエンドサーバー（Node.js など）で実行している場合、SDK は自動で WebSocket を使用します。異なるトランスポート層については [リアルタイムトランスポート](/openai-agents-js/ja/guides/voice-agents/transport) ガイドで詳しく学べます。

6. **すべてをまとめる**

   <Code lang="typescript" code={helloWorldExample} />

7. **エンジンを起動して話し始める**

   Web サーバーを起動し、作成した Realtime エージェントのコードを含むページへアクセスしてください。マイクのアクセス許可を求めるダイアログが表示されます。許可すると、エージェントと会話を始められます。

   ```bash
   npm run dev
   ```

</Steps>

## 次のステップ

ここからは、独自の音声エージェントの設計と構築を進めましょう。音声エージェントは通常のエージェントと多くの機能を共有していますが、いくつか固有の機能もあります。

- 音声エージェントに以下を追加する方法を学ぶ

  - [ツール](/openai-agents-js/ja/guides/voice-agents/build#tools)
  - [ハンドオフ](/openai-agents-js/ja/guides/voice-agents/build#handoffs)
  - [ガードレール](/openai-agents-js/ja/guides/voice-agents/build#guardrails)
  - [音声割り込みの処理](/openai-agents-js/ja/guides/voice-agents/build#audio-interruptions)
  - [セッション履歴の管理](/openai-agents-js/ja/guides/voice-agents/build#session-history)

- 異なるトランスポート層についてさらに学ぶ
  - [ WebRTC ](/openai-agents-js/ja/guides/voice-agents/transport#connecting-over-webrtc)
  - [ WebSocket ](/openai-agents-js/ja/guides/voice-agents/transport#connecting-over-websocket)
  - [独自のトランスポートメカニズムの構築](/openai-agents-js/ja/guides/voice-agents/transport#building-your-own-transport-mechanism)
